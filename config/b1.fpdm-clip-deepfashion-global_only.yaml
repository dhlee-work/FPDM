project_name: 'deepfashion-fusion-CLIP-b48-p005-r10-epoch5-lr1e-5-wd1e-4-globalonly'
root_path: './dataset/deepfashion/'
device: [0]
phase: 'train'
disable_logger: false
mode: 'client'
port: 52162
batch_size: 60 # 70 # 20
num_workers: 16
combiner_hidden_dim: 768  # large 768 base 512
img_pose_drop_rate: 0.0
thr_ratio: 1.0
max_epochs: 5
lr: 0.00001
weight_decay: 0.0001
accumulate_grad_batches: 1
temperature: 0.07
img_size: [224, 224] #[256, 256]
lambda_l1: 0.0001
encoder_type: 'clip' # 'clip'
attn_hidden_dim: 1024  # large-1024 base 768
mh_attn_size: 32
img_encoder_update: true
trained_model_name: null
wandb_id: null
train_dataset_name: 'train_pairs_data.json'
test_dataset_name: 'test_pairs_data.json'
img_encoder_path: 'openai/clip-vit-large-patch14' # 'facebook/dinov2-base' # 'openai/clip-vit-base-patch16'
conbiner_self_learning: true
patch_self_learning: false #
learning_encoder_type: 'all' # 'each',
train_patch_embeddings: false
train_patch_embeddings_sampling_ratio: 0.05 # 0.12 # 0.12 # 0.05

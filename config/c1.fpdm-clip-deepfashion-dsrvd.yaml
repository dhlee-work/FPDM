project_name: 'deepfashion-diffusion-clip-init-wd001-lr1e-4-b32-cum2-size512-noaug-steplr'
#root_path : './dataset/deepfashion/'
disable_logger: False
mode: 'client'
port: 52162
device: [0]
batch_size: 32 # 64
num_workers: 16
lr: 0.0001
accumulate_grad_batches: 2
temperature: 0.07
weight_decay: 0.01
scheduler_t0: 100
scheduler_t_mult: 2
scheduler_eta_max: 0.0001 # 0.0001
scheduler_t_up: 5
scheduler_step_size: 25
scheduler_gamma: 0.1
max_epochs: 100
data_root_path: './dataset/deepfashion'
train_json_path: './dataset/deepfashion/train_pairs_data.json' # train_pairs_data
test_json_path: './dataset/deepfashion/test_pairs_data.json'
phase : 'train'
model_img_size : [512, 512]
img_size: [176, 256]  # (352, 512)
guidance_scale: 2.0
num_inference_steps: 20
seed_number: 7
num_images_per_prompt: 4
test_n_samples: 20
unet_conv_in_kenel: 3
noise_offset: 0.1
module_drop_rate: 0.2
pose_module_drop: false
pose_erase_rate: 0.0 # bad deffect. delete
pose_drop_rate: 0.2
proj_drop_rate: 0.2
embedded_drop_rate: 0.0 # bad deffect. delete
src_encoder_path: 'openai/clip-vit-large-patch14' #'facebook/dinov2-base' # 'openai/clip-vit-base-patch16'
src_encoder_type: 'clip' # 'clip', 'dino'
init_src_image_encoder: true
fusion_image_patch_encoder: true
proj_fusion_image_patch_encoder: true
proj_embds_sum: false
patch_proj_in_dim: 1024
hidden_dim: 768
fusion_image_encoder: true
class_embed_type : 'mlp'  # 'embd-from-mlp' # "projection"
image_proj_in_dim : 768
proj_embd_concat: true
fusion_patch_embed_ahead: false
trained_model_name: null # '2024-06-10T14-09-37' # null # '2024-06-05T00-35-10' #null # '2024-05-30T18-59-18' # '2024-05-28T10-21-27' # null
pretrained_model_name_or_path: 'stabilityai/stable-diffusion-2-1-base'
fusion_model_path: './logs/deepfashion-fusion-CLIP-b48-p005-r10-epoch3-lr1e-5-wd1e-4/2024-06-07T15-11-03/last.ckpt' # './logs/deepfashion-fusion-CLIP-patch-learning/2024-05-28T20-29-57/last.ckpt'
visualize_images: true
calculate_metrics: true
loss_type: 'mse_loss'  # mse_loss, shrinkage_loss
shrinkage_a: 50
shrinkage_c: 0.05
